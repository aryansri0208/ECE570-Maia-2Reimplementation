{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Environment Setup\n",
        "\n",
        "Install all necessary libraries for model training, PGN parsing, Elo conditioning, and plotting. This setup ensures compatibility with the rest of the notebook.\n"
      ],
      "metadata": {
        "id": "HPWLCThqbxXJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqfyXkjEkFCu",
        "outputId": "72fa83cf-50af-4bed-d659-62c00c020680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: chess in /usr/local/lib/python3.11/dist-packages (1.11.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision pandas chess matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PgZ5TC9ltoP"
      },
      "source": [
        "PGN importing and converting to csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ôüÔ∏è PGN Preprocessing Function\n",
        "\n",
        "This function parses PGN files to extract board states (in FEN format), player moves, and their respective Elo ratings. Games are filtered by Elo range to ensure skill-aligned data sampling.\n"
      ],
      "metadata": {
        "id": "QfqT0D9HeXtn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNgIsIH-hFIM",
        "outputId": "d576b016-68f6-4bf7-deda-a5d76f1ec0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Processed 100 games...\n",
            "‚úÖ Processed 200 games...\n",
            "‚úÖ Processed 300 games...\n",
            "‚úÖ Processed 400 games...\n",
            "‚úÖ Processed 500 games...\n",
            "‚úÖ Processed 600 games...\n",
            "‚úÖ Processed 700 games...\n",
            "‚úÖ Processed 800 games...\n",
            "‚úÖ Processed 900 games...\n",
            "‚úÖ Processed 1000 games...\n",
            "Debug: lengths ‚Üí 67309 67309 67309 67309\n",
            "‚úÖ Saved 67309 rows to maia_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import chess.pgn\n",
        "import pandas as pd\n",
        "\n",
        "def extract_fens_from_pgn_file(pgn_path, max_games=1000):\n",
        "    fens, moves, white_elos, black_elos = [], [], [], []\n",
        "\n",
        "    with open(pgn_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as pgn:\n",
        "        game_counter = 0\n",
        "        while game_counter < max_games:\n",
        "            game = chess.pgn.read_game(pgn)\n",
        "            if game is None:\n",
        "                break\n",
        "\n",
        "            board = game.board()\n",
        "\n",
        "            try:\n",
        "                white_elo = int(game.headers.get(\"WhiteElo\", 1500))\n",
        "                black_elo = int(game.headers.get(\"BlackElo\", 1500))\n",
        "            except (ValueError, TypeError):\n",
        "                continue  # skip malformed headers\n",
        "\n",
        "            moves_in_game = list(game.mainline_moves())\n",
        "            if len(moves_in_game) < 2:\n",
        "                continue  # skip very short games\n",
        "\n",
        "            for move in moves_in_game:\n",
        "                fens.append(board.fen())\n",
        "                moves.append(move.uci())\n",
        "                white_elos.append(white_elo)\n",
        "                black_elos.append(black_elo)\n",
        "                board.push(move)\n",
        "\n",
        "            game_counter += 1\n",
        "            if game_counter % 100 == 0:\n",
        "                print(f\"‚úÖ Processed {game_counter} games...\")\n",
        "\n",
        "    return fens, moves, white_elos, black_elos\n",
        "\n",
        "\n",
        "# === Run Safely ===\n",
        "if __name__ == \"__main__\":\n",
        "    pgn_path = \"/content/maia1_sample.pgn\"\n",
        "    fens, moves, white_elos, black_elos = extract_fens_from_pgn_file(pgn_path, max_games=1000)\n",
        "\n",
        "    print(\"Debug: lengths ‚Üí\", len(fens), len(moves), len(white_elos), len(black_elos))\n",
        "\n",
        "    if fens:\n",
        "        df = pd.DataFrame({\n",
        "            \"fen\": fens,\n",
        "            \"move\": moves,\n",
        "            \"white_elo\": white_elos,\n",
        "            \"black_elo\": black_elos\n",
        "        })\n",
        "        df.to_csv(\"maia_dataset.csv\", index=False)\n",
        "        print(f\"‚úÖ Saved {len(df)} rows to maia_dataset.csv\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No data extracted ‚Äî please check the PGN file format and content.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGZs_8SSlvHp"
      },
      "source": [
        "## üß© MaiaChessDataset: Board Encoding and UCI Move Indexing\n",
        "\n",
        "This section defines the core data structure for training the Maia model. It includes:\n",
        "\n",
        "- **FEN to Tensor Conversion**: Each board state is transformed into a 12√ó8√ó8 tensor where each plane represents a piece type (e.g., white pawns, black bishops).\n",
        "- **UCI Move Index Mapping**: A complete set of legal UCI-style move strings (e.g., `e2e4`, `g1f3`) is constructed to create a fixed output vocabulary for the model.\n",
        "- **Dataset Class (`MaiaChessDataset`)**: A PyTorch-compatible dataset that reads a CSV file containing FENs, moves, and Elo ratings. It filters out illegal/unknown moves and returns:\n",
        "  - `board_tensor`: the 12√ó8√ó8 representation of the position\n",
        "  - `elo_tensor`: a 2D tensor containing normalized white and black Elo ratings\n",
        "  - `move_index`: the target move as an integer index in the UCI vocabulary\n",
        "\n",
        "This class is essential for batch processing, data loading, and model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARtlVP3Pl0U5",
        "outputId": "5870a01a-06a5-4304-9ee4-0a4769ec994b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset loaded.\n",
            "Board shape: torch.Size([12, 8, 8])\n",
            "Elo tensor: tensor([0.4890, 0.4787])\n",
            "Move index: 2147\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import chess\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# === PIECE TO PLANE MAPPING ===\n",
        "piece_to_plane = {\n",
        "    \"P\": 0, \"N\": 1, \"B\": 2, \"R\": 3, \"Q\": 4, \"K\": 5,\n",
        "    \"p\": 6, \"n\": 7, \"b\": 8, \"r\": 9, \"q\": 10, \"k\": 11\n",
        "}\n",
        "\n",
        "def fen_to_tensor(fen):\n",
        "    board = chess.Board(fen)\n",
        "    tensor = torch.zeros((12, 8, 8), dtype=torch.float32)\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "        if piece:\n",
        "            row = 7 - square // 8\n",
        "            col = square % 8\n",
        "            plane = piece_to_plane[piece.symbol()]\n",
        "            tensor[plane, row, col] = 1\n",
        "    return tensor\n",
        "\n",
        "# === UCI MOVE TO INDEX MAPPING ===\n",
        "# We‚Äôll use a reference board to get all possible UCIs\n",
        "def get_all_possible_uci_moves():\n",
        "    board = chess.Board()\n",
        "    all_moves = set()\n",
        "    for move in board.legal_moves:\n",
        "        all_moves.add(move.uci())\n",
        "    # Expand by making fake moves across board to build full space\n",
        "    for from_sq in chess.SQUARE_NAMES:\n",
        "        for to_sq in chess.SQUARE_NAMES:\n",
        "            all_moves.add(from_sq + to_sq)\n",
        "    return sorted(all_moves)\n",
        "\n",
        "ALL_MOVES = get_all_possible_uci_moves()\n",
        "uci_to_index = {uci: idx for idx, uci in enumerate(ALL_MOVES)}\n",
        "\n",
        "def move_to_index(move_uci):\n",
        "    return uci_to_index.get(move_uci, -1)  # -1 for unknown/illegal\n",
        "\n",
        "# === PYTORCH DATASET ===\n",
        "class MaiaChessDataset(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.valid_data = self.data[self.data[\"move\"].apply(lambda m: move_to_index(m) != -1)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.valid_data.iloc[idx]\n",
        "        board_tensor = fen_to_tensor(row[\"fen\"])  # shape: [12, 8, 8]\n",
        "        white_elo, black_elo = row[\"white_elo\"], row[\"black_elo\"]\n",
        "        elo_tensor = torch.tensor([white_elo / 3000, black_elo / 3000], dtype=torch.float32)  # shape: [2]\n",
        "        move_index = move_to_index(row[\"move\"])  # int in [0, 4671]\n",
        "        return board_tensor, elo_tensor, move_index\n",
        "\n",
        "\n",
        "\n",
        "# === QUICK TEST ===\n",
        "if __name__ == \"__main__\":\n",
        "    dataset = MaiaChessDataset(\"maia_dataset.csv\")\n",
        "    board_tensor, elo_tensor, move_index = dataset[0]\n",
        "    print(\"‚úÖ Dataset loaded.\")\n",
        "    print(\"Board shape:\", board_tensor.shape)   # expected outcome [12, 8, 8]\n",
        "    print(\"Elo tensor:\", elo_tensor)            # [2]\n",
        "    print(\"Move index:\", move_index)            # int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jKRiz5iluxb"
      },
      "source": [
        "Maia Initial (Deprecated Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† MaiaCNN (v0): Convolutional Neural Network for Move Prediction\n",
        "\n",
        "This is the baseline CNN architecture for predicting human chess moves given board state inputs. It processes a 12√ó8√ó8 tensor representing the chessboard (one channel per piece type and color).\n",
        "\n",
        "### Architecture Overview:\n",
        "- **3 Convolutional Layers**:\n",
        "  - `conv1`: 12 ‚Üí 32 channels\n",
        "  - `conv2`: 32 ‚Üí 64 channels\n",
        "  - `conv3`: 64 ‚Üí 128 channels\n",
        "- **Max Pooling**: Reduces spatial resolution after the first conv layer (from 8√ó8 ‚Üí 4√ó4)\n",
        "- **Fully Connected Layers**:\n",
        "  - `fc1`: Intermediate 512-dimensional hidden representation\n",
        "  - `fc2`: Outputs logits over the move class space (default 4672 classes)\n",
        "  \n",
        "### Output:\n",
        "The model returns unnormalized logits which can be passed to `CrossEntropyLoss` for training.\n",
        "\n",
        "This CNN serves as a baseline for skill-unaware prediction. More advanced versions may include Elo-conditioning or attention mechanisms.\n"
      ],
      "metadata": {
        "id": "UJ09H7tpe8eg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtFJzKMomSi1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MaiaCNN(nn.Module):\n",
        "    def __init__(self, num_classes=4672):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x: [batch, 12, 8, 8]\n",
        "        x = F.relu(self.conv1(x))   # -> [batch, 32, 8, 8]\n",
        "        x = self.pool(x)            # -> [batch, 32, 4, 4]\n",
        "        x = F.relu(self.conv2(x))   # -> [batch, 64, 4, 4]\n",
        "        x = F.relu(self.conv3(x))   # -> [batch, 128, 4, 4]\n",
        "        x = x.view(-1, 128 * 4 * 4) # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)          # Output: logits over move classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--d75WrOmkXn"
      },
      "source": [
        "## üèãÔ∏è‚Äç‚ôÇÔ∏è Training and Evaluation Loop\n",
        "\n",
        "This section trains the `MaiaCNN` model on a dataset of FEN positions and associated UCI moves. The training process includes:\n",
        "\n",
        "### üìã Components:\n",
        "\n",
        "- **Configuration Parameters**:\n",
        "  - `BATCH_SIZE`: number of samples per training batch\n",
        "  - `EPOCHS`: total number of training iterations\n",
        "  - `LR`: learning rate for the optimizer\n",
        "  - `NUM_CLASSES`: total number of move classes in the output layer\n",
        "\n",
        "- **Train/Validation Split**:\n",
        "  The dataset is split into an 80/20 training-validation ratio using PyTorch's `random_split`.\n",
        "\n",
        "- **Model, Loss, and Optimizer**:\n",
        "  - The model is an instance of `MaiaCNN`\n",
        "  - Loss is computed via `CrossEntropyLoss`\n",
        "  - Optimization is performed using the Adam optimizer\n",
        "\n",
        "- **Training Loop**:\n",
        "  For each epoch, the model performs:\n",
        "  - Forward pass on training data\n",
        "  - Loss computation\n",
        "  - Backpropagation\n",
        "  - Parameter updates via gradient descent\n",
        "\n",
        "- **Validation Loop**:\n",
        "  After each epoch, the model evaluates on the validation set using:\n",
        "  - **Top-1 Accuracy**: correct move is the highest predicted probability\n",
        "  - **Top-3 / Top-5 Accuracy**: correct move appears in the top-3 or top-5 predictions\n",
        "\n",
        "- **Model Saving**:\n",
        "  The model's weights and optimizer state are saved to a `.pth` file after training for reproducibility and future inference.\n",
        "\n",
        "This pipeline evaluates how well the model mimics human play based on chess position inputs.\n",
        "\n",
        "## üèÅ Training Results and Evaluation\n",
        "\n",
        "After 5 epochs of training the `MaiaCNN` model on a dataset of 1000 human chess games, the model achieved the following results on the validation set:\n",
        "\n",
        "\n",
        "### üéØ Expected Accuracy Range\n",
        "\n",
        "For a model predicting among ~4,672 UCI move classes with no pretrained weights:\n",
        "\n",
        "| Metric          | Expected Range (Small Dataset) |\n",
        "|------------------|------------------------------|\n",
        "| Top-1 Accuracy   | 5‚Äì15%                         |\n",
        "| Top-3 Accuracy   | 10‚Äì25%                        |\n",
        "| Top-5 Accuracy   | 15‚Äì30%                        |\n",
        "\n",
        "These results are **in line with expectations** for:\n",
        "- A relatively **small dataset** (only ~1000 games, ~35k‚Äì40k positions)\n",
        "- A **non-pretrained model**\n",
        "- Limited training time (only **5 epochs**)\n",
        "- Running on **basic GPU environments**\n",
        "\n",
        "### üìå Justification for Low Top-1 Accuracy\n",
        "\n",
        "- Human chess move prediction is a highly multi-class problem (~4.6k+ classes)\n",
        "- Even in the original [Maia paper](https://arxiv.org/abs/2009.04374), Top-1 accuracy for well-trained models ranged between 18‚Äì28% depending on Elo\n",
        "- Without large-scale pretraining or ensembling, models on small data are expected to remain below 15% Top-1 accuracy\n",
        "\n",
        "> üîÅ These metrics can be significantly improved by increasing dataset size, using pretrained Maia weights, or fine-tuning for longer epochs on GPU-backed hardware.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyDJeH11mbK0",
        "outputId": "323f02e4-285c-4f0e-ef8e-79aa0f055468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss: 6.3710\n",
            "Top-1 Acc: 4.87% | Top-3 Acc: 9.79% | Top-5 Acc: 12.68%\n",
            "Epoch 2/5 - Loss: 5.9097\n",
            "Top-1 Acc: 6.78% | Top-3 Acc: 13.69% | Top-5 Acc: 17.46%\n",
            "Epoch 3/5 - Loss: 5.5364\n",
            "Top-1 Acc: 8.93% | Top-3 Acc: 16.98% | Top-5 Acc: 21.86%\n",
            "Epoch 4/5 - Loss: 5.1259\n",
            "Top-1 Acc: 10.85% | Top-3 Acc: 20.14% | Top-5 Acc: 25.13%\n",
            "Epoch 5/5 - Loss: 4.7693\n",
            "Top-1 Acc: 11.83% | Top-3 Acc: 21.61% | Top-5 Acc: 26.86%\n",
            "‚úÖ Model saved to maia_model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# === Top-k Accuracy Helper ===\n",
        "def top_k_accuracy(outputs, targets, k=5):\n",
        "    _, topk_preds = torch.topk(outputs, k, dim=1)\n",
        "    matches = topk_preds.eq(targets.view(-1, 1))\n",
        "    return matches.any(dim=1).float().mean().item()\n",
        "\n",
        "# === Config ===\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "LR = 0.001\n",
        "NUM_CLASSES = 4672\n",
        "\n",
        "# === Dataset & Split ===\n",
        "dataset = MaiaChessDataset(\"maia_dataset.csv\")\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "# === Model, Loss, Optimizer ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MaiaCNN(num_classes=NUM_CLASSES).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# === Training + Validation Loop ===\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for board_tensor, _, move_index in train_loader:\n",
        "\n",
        "        board_tensor, move_index = board_tensor.to(device), move_index.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(board_tensor)\n",
        "        loss = criterion(outputs, move_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # === Validation with Top-k Metrics ===\n",
        "    model.eval()\n",
        "    top1_correct = 0\n",
        "    top3_acc = 0\n",
        "    top5_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for board_tensor, _, move_index in val_loader:\n",
        "            board_tensor, move_index = board_tensor.to(device), move_index.to(device)\n",
        "            outputs = model(board_tensor)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            top1_correct += (preds == move_index).sum().item()\n",
        "            top3_acc += top_k_accuracy(outputs, move_index, k=3) * move_index.size(0)\n",
        "            top5_acc += top_k_accuracy(outputs, move_index, k=5) * move_index.size(0)\n",
        "            total += move_index.size(0)\n",
        "\n",
        "    top1 = top1_correct / total\n",
        "    top3 = top3_acc / total\n",
        "    top5 = top5_acc / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Top-1 Acc: {top1*100:.2f}% | Top-3 Acc: {top3*100:.2f}% | Top-5 Acc: {top5*100:.2f}%\")\n",
        "\n",
        "# === Save model after training ===\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, \"maia_model.pth\")\n",
        "\n",
        "print(\"‚úÖ Model saved to maia_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxZghXv0oMF9"
      },
      "source": [
        "## üß† MaiaCNN (v1): Elo-Aware CNN Training for Human Chess Move Prediction\n",
        "\n",
        "This experiment implements a skill-aware variant of the Maia CNN architecture. The model is trained on a filtered dataset of chess games (in FEN format) with associated UCI moves and Elo ratings.\n",
        "\n",
        "### ‚úÖ Key Components:\n",
        "- **`MaiaChessDataset`**: A custom PyTorch dataset that:\n",
        "  - Loads FENs and moves from `maia_dataset.csv`\n",
        "  - Encodes the board as a 12√ó8√ó8 tensor\n",
        "  - Converts white and black Elo ratings into a normalized 2D tensor\n",
        "- **`MaiaCNN`**:\n",
        "  - A convolutional neural network that processes board state features\n",
        "  - Concatenates the Elo tensor before the first fully connected layer\n",
        "  - Predicts a move index from ~4.6k possible UCI moves\n",
        "\n",
        "### ‚öôÔ∏è Training Configuration:\n",
        "- Epochs: 5  \n",
        "- Batch size: 64  \n",
        "- Optimizer: Adam  \n",
        "- Loss function: CrossEntropyLoss  \n",
        "- Top-k accuracy metrics tracked for evaluation\n",
        "\n",
        "---\n",
        "\n",
        "### üìà Training Results\n",
        "\n",
        "### üéØ Expected Performance & Justification\n",
        "\n",
        "These results are consistent with the expected performance for this setup:\n",
        "\n",
        "| Metric          | Expected Range (small-scale) |\n",
        "|------------------|------------------------------|\n",
        "| Top-1 Accuracy   | 5‚Äì15%                         |\n",
        "| Top-3 Accuracy   | 10‚Äì25%                        |\n",
        "| Top-5 Accuracy   | 15‚Äì30%                        |\n",
        "\n",
        "> üìâ The relatively low Top-1 accuracy is justified due to:\n",
        "> - A small training set (~1000 games, ~40k positions)\n",
        "> - A large output class space (~4672 legal UCI moves)\n",
        "> - Training from scratch (no pretrained weights)\n",
        "> - Limited number of epochs (5)\n",
        "\n",
        "For reference, the original Maia-1500 model reported ~19‚Äì20% Top-1 accuracy after training on millions of positions.\n",
        "\n",
        "---\n",
        "\n",
        "### üíæ Model Export\n",
        "The trained model is saved as: maia_elo_model.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBECmb-rmmUc",
        "outputId": "50e8aae0-5b7a-45cd-c54d-c428a5e26334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss: 6.3989\n",
            "Top-1 Acc: 3.91% | Top-3 Acc: 9.25% | Top-5 Acc: 11.92%\n",
            "Epoch 2/5 - Loss: 5.9659\n",
            "Top-1 Acc: 6.52% | Top-3 Acc: 12.65% | Top-5 Acc: 16.05%\n",
            "Epoch 3/5 - Loss: 5.6131\n",
            "Top-1 Acc: 8.58% | Top-3 Acc: 16.16% | Top-5 Acc: 20.68%\n",
            "Epoch 4/5 - Loss: 5.2000\n",
            "Top-1 Acc: 10.46% | Top-3 Acc: 19.63% | Top-5 Acc: 24.48%\n",
            "Epoch 5/5 - Loss: 4.8355\n",
            "Top-1 Acc: 11.80% | Top-3 Acc: 21.33% | Top-5 Acc: 26.77%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "ALL_MOVES = get_all_possible_uci_moves()\n",
        "uci_to_index = {uci: idx for idx, uci in enumerate(ALL_MOVES)}\n",
        "\n",
        "class MaiaChessDataset(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.valid_data = self.data[self.data[\"move\"].apply(lambda m: move_to_index(m) != -1)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.valid_data.iloc[idx]\n",
        "        board_tensor = fen_to_tensor(row[\"fen\"])\n",
        "        white_elo, black_elo = row[\"white_elo\"], row[\"black_elo\"]\n",
        "        elo_tensor = self.elo_to_tensor(white_elo, black_elo)\n",
        "        move_index = move_to_index(row[\"move\"])\n",
        "        return board_tensor, elo_tensor, move_index\n",
        "\n",
        "    def elo_to_tensor(self, white_elo, black_elo):\n",
        "        max_elo = 2800\n",
        "        white_elo_scaled = float(white_elo) / max_elo\n",
        "        black_elo_scaled = float(black_elo) / max_elo\n",
        "        return torch.tensor([white_elo_scaled, black_elo_scaled], dtype=torch.float32)\n",
        "\n",
        "class MaiaCNN(nn.Module):\n",
        "    def __init__(self, num_classes=4672):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4 + 2, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x, elo_tensor):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = torch.cat((x, elo_tensor), dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "def top_k_accuracy(outputs, targets, k=5):\n",
        "    _, topk_preds = torch.topk(outputs, k, dim=1)\n",
        "    matches = topk_preds.eq(targets.view(-1, 1))\n",
        "    return matches.any(dim=1).float().mean().item()\n",
        "\n",
        "# Config\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "LR = 0.001\n",
        "NUM_CLASSES = 4672\n",
        "\n",
        "# Dataset & Loaders\n",
        "dataset = MaiaChessDataset(\"maia_dataset.csv\")\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MaiaCNN(num_classes=NUM_CLASSES).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# Training\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X, elo, y in train_loader:\n",
        "        X, elo, y = X.to(device), elo.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X, elo)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    top1_correct = 0\n",
        "    top3_acc = 0\n",
        "    top5_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, elo, y in val_loader:\n",
        "            X, elo, y = X.to(device), elo.to(device), y.to(device)\n",
        "            outputs = model(X, elo)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            top1_correct += (preds == y).sum().item()\n",
        "            top3_acc += top_k_accuracy(outputs, y, k=3) * y.size(0)\n",
        "            top5_acc += top_k_accuracy(outputs, y, k=5) * y.size(0)\n",
        "            total += y.size(0)\n",
        "\n",
        "    top1 = top1_correct / total\n",
        "    top3 = top3_acc / total\n",
        "    top5 = top5_acc / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Top-1 Acc: {top1*100:.2f}% | Top-3 Acc: {top3*100:.2f}% | Top-5 Acc: {top5*100:.2f}%\")\n",
        "torch.save({\"model_state_dict\": model.state_dict()}, \"maia_elo_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhgbKNh8oaA2"
      },
      "source": [
        "## üß† MaiaCNN (v2) with Skill-Aware Channel-Wise Attention\n",
        "\n",
        "This architecture extends the baseline Maia convolutional network by incorporating **skill-aware attention**, allowing the model to condition its internal feature activations on player Elo ratings. This enables the network to specialize its representations for different skill levels.\n",
        "\n",
        "### üìê Architecture Components\n",
        "\n",
        "- **Convolutional Layers**:\n",
        "  - Three convolutional layers with increasing channel depth (32 ‚Üí 64 ‚Üí 128)\n",
        "  - One MaxPooling layer reduces spatial resolution from 8√ó8 to 4√ó4\n",
        "\n",
        "- **Elo Projection and Attention**:\n",
        "  - The player Elo vector (white and black Elo) is passed through a small MLP (`elo_proj ‚Üí attention_weight`)\n",
        "  - The resulting 128-dimensional attention vector modulates the feature maps **channel-wise** via element-wise multiplication\n",
        "\n",
        "- **Fully Connected Layers**:\n",
        "  - The output of the final conv layer (shape `[B, 128, 4, 4]`) is flattened\n",
        "  - One fully connected layer reduces this to a 512-dimensional feature vector\n",
        "  - The final layer maps to `num_classes` UCI move logits\n",
        "\n",
        "### üéØ Purpose\n",
        "\n",
        "The attention mechanism allows the model to:\n",
        "- Emphasize different filters based on **skill level**\n",
        "- Learn **skill-sensitive patterns** of decision-making (e.g., low-Elo blunders vs high-Elo precision)\n",
        "\n",
        "### üßÆ Output\n",
        "\n",
        "The model outputs unnormalized logits over ~4672 move classes. These can be passed into a `CrossEntropyLoss` during training.\n",
        "\n",
        "> This model aligns with Maia's core philosophy: **predict the move a human would make**, not the optimal engine move ‚Äî and personalize that prediction based on Elo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0fdO463oPkt"
      },
      "outputs": [],
      "source": [
        "class MaiaCNN(nn.Module):\n",
        "    def __init__(self, num_classes=4672, elo_dim=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Attention layers\n",
        "        self.elo_proj = nn.Linear(elo_dim, 128)  # project Elo vector\n",
        "        self.attention_weight = nn.Linear(128, 128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, board_tensor, elo_tensor):\n",
        "        x = F.relu(self.conv1(board_tensor))        # [B, 32, 8, 8]\n",
        "        x = self.pool(F.relu(self.conv2(x)))        # [B, 64, 4, 4]\n",
        "        x = F.relu(self.conv3(x))                   # [B, 128, 4, 4]\n",
        "\n",
        "        # Skill-aware attention\n",
        "        B, C, H, W = x.shape\n",
        "        elo_embed = self.elo_proj(elo_tensor)       # [B, 128]\n",
        "        attention = torch.sigmoid(self.attention_weight(elo_embed)).view(B, C, 1, 1)\n",
        "        x = x * attention                           # apply attention across channels\n",
        "\n",
        "        x = x.view(B, -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèãÔ∏è‚Äç‚ôÇÔ∏è Training and Evaluation: Skill-Aware Elo-Attentive MaiaCNN\n",
        "\n",
        "This section trains the **Elo-aware MaiaCNN model** with a channel-wise attention mechanism. The model takes in both board state tensors and Elo vectors as inputs, modulates internal activations based on Elo, and predicts the most likely human move.\n",
        "\n",
        "### ‚öôÔ∏è Training Configuration\n",
        "\n",
        "| Parameter   | Value      |\n",
        "|-------------|------------|\n",
        "| Dataset     | `maia_dataset.csv` (preprocessed PGN data) |\n",
        "| Model       | `MaiaCNN` with skill-aware attention |\n",
        "| Epochs      | 5          |\n",
        "| Batch Size  | 64         |\n",
        "| Learning Rate | 0.001    |\n",
        "| Loss        | `CrossEntropyLoss` |\n",
        "| Optimizer   | `Adam`     |\n",
        "| Device      | GPU if available, else CPU |\n",
        "\n",
        "Top-1, Top-3, and Top-5 accuracy metrics are computed on a validation split after each epoch to evaluate the model‚Äôs ability to replicate human move selection.\n",
        "\n",
        "---\n",
        "\n",
        "### üìà Training Results\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Expected Performance and Interpretation\n",
        "\n",
        "These results fall within the expected performance bounds for models trained from scratch on a relatively small dataset (~1000 games):\n",
        "\n",
        "| Metric         | Expected Range (small-scale) |\n",
        "|----------------|------------------------------|\n",
        "| Top-1 Accuracy | 5‚Äì15%                        |\n",
        "| Top-3 Accuracy | 10‚Äì25%                       |\n",
        "| Top-5 Accuracy | 15‚Äì30%                       |\n",
        "\n",
        "> The improvement in accuracy across epochs and the consistent decrease in loss indicate that the model is effectively learning to emulate human move preferences within its constrained setting.\n",
        "\n",
        "#### Why Top-1 is \"Low\":\n",
        "- ‚úÖ Large output space (~4.6k UCI move classes)\n",
        "- ‚úÖ No pretraining (training from scratch)\n",
        "- ‚úÖ Dataset size is limited (small number of human games)\n",
        "- ‚úÖ Only 5 training epochs\n",
        "\n",
        "---\n",
        "\n",
        "### üíæ Saved Model\n",
        "\n",
        "The final model checkpoint has been saved as: maia_elo_attn.pth\n",
        "\n"
      ],
      "metadata": {
        "id": "eus20YVohxmW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk6iamr2pOI3",
        "outputId": "c32a065b-e19a-4e8d-ab73-3f652ee521e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss: 6.3843\n",
            "Top-1 Acc: 5.16% | Top-3 Acc: 9.85% | Top-5 Acc: 12.45%\n",
            "Epoch 2/5 - Loss: 5.9176\n",
            "Top-1 Acc: 6.79% | Top-3 Acc: 13.33% | Top-5 Acc: 16.92%\n",
            "Epoch 3/5 - Loss: 5.5857\n",
            "Top-1 Acc: 8.70% | Top-3 Acc: 16.22% | Top-5 Acc: 20.65%\n",
            "Epoch 4/5 - Loss: 5.1617\n",
            "Top-1 Acc: 10.62% | Top-3 Acc: 20.27% | Top-5 Acc: 25.38%\n",
            "Epoch 5/5 - Loss: 4.6967\n",
            "Top-1 Acc: 13.28% | Top-3 Acc: 23.52% | Top-5 Acc: 29.38%\n",
            "‚úÖ Model saved to maia_elo_attn.pth\n"
          ]
        }
      ],
      "source": [
        "# === Top-k Accuracy Helper ===\n",
        "def top_k_accuracy(outputs, targets, k=5):\n",
        "    _, topk_preds = torch.topk(outputs, k, dim=1)\n",
        "    matches = topk_preds.eq(targets.view(-1, 1))\n",
        "    return matches.any(dim=1).float().mean().item()\n",
        "\n",
        "# === Config ===\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "LR = 0.001\n",
        "NUM_CLASSES = 4672\n",
        "\n",
        "# === Dataset & Split ===\n",
        "dataset = MaiaChessDataset(\"maia_dataset.csv\")\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "# === Model, Loss, Optimizer ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MaiaCNN(num_classes=NUM_CLASSES).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# === Training + Validation Loop ===\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for board_tensor, elo_tensor, move_index in train_loader:\n",
        "        board_tensor, elo_tensor, move_index = board_tensor.to(device), elo_tensor.to(device), move_index.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(board_tensor, elo_tensor)\n",
        "        loss = criterion(outputs, move_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # === Validation with Top-k Metrics ===\n",
        "    model.eval()\n",
        "    top1_correct = 0\n",
        "    top3_acc = 0\n",
        "    top5_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for board_tensor, elo_tensor, move_index in val_loader:\n",
        "            board_tensor, elo_tensor, move_index = board_tensor.to(device), elo_tensor.to(device), move_index.to(device)\n",
        "            outputs = model(board_tensor, elo_tensor)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            top1_correct += (preds == move_index).sum().item()\n",
        "            top3_acc += top_k_accuracy(outputs, move_index, k=3) * move_index.size(0)\n",
        "            top5_acc += top_k_accuracy(outputs, move_index, k=5) * move_index.size(0)\n",
        "            total += move_index.size(0)\n",
        "\n",
        "    top1 = top1_correct / total\n",
        "    top3 = top3_acc / total\n",
        "    top5 = top5_acc / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Top-1 Acc: {top1*100:.2f}% | Top-3 Acc: {top3*100:.2f}% | Top-5 Acc: {top5*100:.2f}%\")\n",
        "\n",
        "# === Save model after training ===\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, \"maia_elo_attn.pth\")\n",
        "\n",
        "print(\"‚úÖ Model saved to maia_elo_attn.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NfjLIcfqRW0"
      },
      "source": [
        "## üß† Training Elo-Bucketed Skill-Aware CNN Models (Maia-2)\n",
        "\n",
        "This script defines the full pipeline to train **Elo-personalized MaiaCNN models** with skill-aware attention over different Elo ranges. The approach allows modeling how players at different skill levels (e.g., 1300‚Äì1400, 1500‚Äì1600) choose moves, enabling human-aligned prediction.\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Overview\n",
        "\n",
        "This pipeline includes:\n",
        "\n",
        "1. **PGN Parsing**  \n",
        "   - Extracts FEN board states, UCI moves, and Elo ratings from `.pgn` game files\n",
        "   - Filters games within the target Elo range (default: 1300‚Äì2000)\n",
        "\n",
        "2. **Move Vocabulary Setup**  \n",
        "   - Builds a universal list of UCI move strings (`uci_to_idx`) used as output classes\n",
        "\n",
        "3. **FEN to Tensor Converter**  \n",
        "   - Encodes board states into a 12√ó8√ó8 PyTorch tensor using one-hot encoding of piece types\n",
        "\n",
        "4. **Model Definition: `MaiaCNN` with Attention**  \n",
        "   - Convolutional layers for board encoding\n",
        "   - Elo-aware **channel-wise attention mechanism** modulates the feature maps based on player skill\n",
        "   - Fully connected layers produce logits over UCI move classes\n",
        "\n",
        "5. **Training Function `train_over_elo_buckets(...)`**  \n",
        "   - For each Elo bucket (e.g., 1300‚Äì1400), a new dataset and model are instantiated\n",
        "   - Trains for a fixed number of epochs (default: 5) with Adam optimizer and label-smoothing loss\n",
        "   - Saves a `.pth` checkpoint for each trained model\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Motivation\n",
        "\n",
        "Chess behavior differs dramatically by Elo: lower-rated players blunder more, while higher-rated players demonstrate deeper tactics. By fine-tuning one model per Elo segment:\n",
        "\n",
        "- We improve **human-likeness** of predictions\n",
        "- We can later evaluate **skill-alignment** in move distributions\n",
        "- Enables plug-and-play inference for **adaptive chess tutors** or Elo-calibrated analysis tools\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Output\n",
        "\n",
        "Each trained model is saved to disk under: maia_finetuned_elo_<elo_min>_<elo_max>.pth\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77wn0ah-pSwa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import chess.pgn\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# === Preprocessing ===\n",
        "def extract_fens_and_moves(pgn_file, max_games=100000, elo_range=(1300, 2000)):\n",
        "    fens, moves, white_elos, black_elos = [], [], [], []\n",
        "    with open(pgn_file, \"r\", encoding=\"utf-8\", errors=\"replace\") as pgn:\n",
        "        game_counter = 0\n",
        "        while game_counter < max_games:\n",
        "            game = chess.pgn.read_game(pgn)\n",
        "            if game is None:\n",
        "                break\n",
        "            board = game.board()\n",
        "            try:\n",
        "                white_elo = int(game.headers.get(\"WhiteElo\", 1500))\n",
        "                black_elo = int(game.headers.get(\"BlackElo\", 1500))\n",
        "            except:\n",
        "                continue\n",
        "            if not (elo_range[0] <= white_elo <= elo_range[1] and elo_range[0] <= black_elo <= elo_range[1]):\n",
        "                continue\n",
        "            for move in game.mainline_moves():\n",
        "                fens.append(board.fen())\n",
        "                moves.append(move.uci())\n",
        "                white_elos.append(white_elo)\n",
        "                black_elos.append(black_elo)\n",
        "                board.push(move)\n",
        "            game_counter += 1\n",
        "    return pd.DataFrame({\"fen\": fens, \"move\": moves, \"white_elo\": white_elos, \"black_elo\": black_elos})\n",
        "\n",
        "# === Move mapping ===\n",
        "uci_moves = sorted({f + t for f in chess.SQUARE_NAMES for t in chess.SQUARE_NAMES})\n",
        "uci_to_idx = {uci: idx for idx, uci in enumerate(uci_moves)}\n",
        "\n",
        "# === Board Tensor Converter ===\n",
        "def fen_to_tensor(fen):\n",
        "    piece_to_plane = {\n",
        "        \"P\": 0, \"N\": 1, \"B\": 2, \"R\": 3, \"Q\": 4, \"K\": 5,\n",
        "        \"p\": 6, \"n\": 7, \"b\": 8, \"r\": 9, \"q\": 10, \"k\": 11\n",
        "    }\n",
        "    import chess\n",
        "    board = chess.Board(fen)\n",
        "    tensor = torch.zeros((12, 8, 8), dtype=torch.float32)\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "        if piece:\n",
        "            row = 7 - square // 8\n",
        "            col = square % 8\n",
        "            tensor[piece_to_plane[piece.symbol()], row, col] = 1\n",
        "    return tensor\n",
        "\n",
        "# === Model Definition ===\n",
        "class MaiaCNN(nn.Module):\n",
        "    def __init__(self, num_classes=4672, elo_dim=2):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(12, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Attention layers\n",
        "        self.elo_proj = nn.Linear(elo_dim, 128)  # project Elo vector\n",
        "        self.attention_weight = nn.Linear(128, 128)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, board_tensor, elo_tensor):\n",
        "        x = F.relu(self.conv1(board_tensor))        # [B, 32, 8, 8]\n",
        "        x = self.pool(F.relu(self.conv2(x)))        # [B, 64, 4, 4]\n",
        "        x = F.relu(self.conv3(x))                   # [B, 128, 4, 4]\n",
        "\n",
        "        # Skill-aware attention\n",
        "        B, C, H, W = x.shape\n",
        "        elo_embed = self.elo_proj(elo_tensor)       # [B, 128]\n",
        "        attention = torch.sigmoid(self.attention_weight(elo_embed)).view(B, C, 1, 1)\n",
        "        x = x * attention                           # apply attention across channels\n",
        "\n",
        "        x = x.view(B, -1)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# === Trainer Function Per Elo Bucket ===\n",
        "def train_over_elo_buckets(df, uci_to_idx, model_class, elo_ranges, epochs=5, batch_size=64, save_prefix=\"maia_finetuned\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for elo_min, elo_max in elo_ranges:\n",
        "        print(f\"\\nüéØ Training on Elo bucket: {elo_min}‚Äì{elo_max}\")\n",
        "\n",
        "        # Filter\n",
        "        bucket_df = df[\n",
        "            (df[\"white_elo\"].between(elo_min, elo_max)) &\n",
        "            (df[\"black_elo\"].between(elo_min, elo_max)) &\n",
        "            (df[\"move\"].isin(uci_to_idx))\n",
        "        ].reset_index(drop=True)\n",
        "\n",
        "        if len(bucket_df) < 100:\n",
        "            print(f\"‚ö†Ô∏è Skipping {elo_min}-{elo_max} (only {len(bucket_df)} samples)\")\n",
        "            continue\n",
        "\n",
        "        # Dataset\n",
        "        class BucketDataset(Dataset):\n",
        "            def __init__(self, df):\n",
        "                self.df = df\n",
        "\n",
        "            def __len__(self): return len(self.df)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                row = self.df.iloc[idx]\n",
        "                board_tensor = fen_to_tensor(row[\"fen\"])\n",
        "                elo_tensor = torch.tensor([row.white_elo/3000, row.black_elo/3000], dtype=torch.float32)\n",
        "                move_index = uci_to_idx[row[\"move\"]]\n",
        "                return board_tensor, elo_tensor, move_index\n",
        "\n",
        "        dataset = BucketDataset(bucket_df)\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        val_size = len(dataset) - train_size\n",
        "        train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "\n",
        "        # Init\n",
        "        model = model_class(num_classes=len(uci_to_idx)).to(device)\n",
        "        loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss, correct, total = 0, 0, 0\n",
        "            for board_tensor, elo_tensor, move_index in train_loader:\n",
        "                board_tensor, elo_tensor, move_index = board_tensor.to(device), elo_tensor.to(device), move_index.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(board_tensor, elo_tensor)\n",
        "                loss = loss_fn(outputs, move_index)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                correct += (outputs.argmax(dim=1) == move_index).sum().item()\n",
        "                total += move_index.size(0)\n",
        "\n",
        "            acc = 100 * correct / total\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f} - Top-1 Acc: {acc:.2f}%\")\n",
        "\n",
        "        model_path = f\"{save_prefix}_elo_{elo_min}_{elo_max}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"‚úÖ Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Elo-Bucketed Training Execution\n",
        "\n",
        "This block runs the complete training routine over **defined Elo segments** using the previously defined `train_over_elo_buckets()` function.\n",
        "\n",
        "### ‚úÖ Process Summary:\n",
        "\n",
        "1. **Dataset Loading**  \n",
        "   Parses and processes up to 1000 games from the PGN file `maia1_sample.pgn`, extracting board states (FEN), moves, and player Elo ratings.\n",
        "\n",
        "2. **Elo Range Definition**  \n",
        "   The dataset is split into five distinct Elo buckets of width 100:\n",
        "   - 1400‚Äì1500\n",
        "   - 1500‚Äì1600\n",
        "   - 1600‚Äì1700\n",
        "   - 1700‚Äì1800\n",
        "   - 1800‚Äì1900\n",
        "\n",
        "3. **Model Training per Bucket**  \n",
        "   For each Elo bucket:\n",
        "   - A dataset subset is extracted\n",
        "   - A new instance of the skill-aware `MaiaCNN` model is initialized\n",
        "   - The model is trained for 5 epochs\n",
        "   - A checkpoint is saved using the prefix `maia_finetuned`\n",
        "\n",
        "### üíæ Output\n",
        "\n",
        "Each model is saved under: maia_finetuned_elo_<min>_<max>.pth"
      ],
      "metadata": {
        "id": "sTqwR2dzj2Yb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlespdtAxUP7",
        "outputId": "b76040e7-4421-4ef7-b5d7-a65100fd7a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ Training on Elo bucket: 1400‚Äì1500\n",
            "Epoch 1/5 - Loss: 7.4043 - Top-1 Acc: 1.08%\n",
            "Epoch 2/5 - Loss: 6.8350 - Top-1 Acc: 1.21%\n",
            "Epoch 3/5 - Loss: 6.7903 - Top-1 Acc: 1.32%\n",
            "Epoch 4/5 - Loss: 6.7487 - Top-1 Acc: 2.11%\n",
            "Epoch 5/5 - Loss: 6.6754 - Top-1 Acc: 2.52%\n",
            "‚úÖ Model saved to maia_finetuned_elo_1400_1500.pth\n",
            "\n",
            "üéØ Training on Elo bucket: 1500‚Äì1600\n",
            "Epoch 1/5 - Loss: 7.5219 - Top-1 Acc: 1.21%\n",
            "Epoch 2/5 - Loss: 6.8280 - Top-1 Acc: 1.42%\n",
            "Epoch 3/5 - Loss: 6.7872 - Top-1 Acc: 1.31%\n",
            "Epoch 4/5 - Loss: 6.7624 - Top-1 Acc: 1.35%\n",
            "Epoch 5/5 - Loss: 6.7249 - Top-1 Acc: 1.96%\n",
            "‚úÖ Model saved to maia_finetuned_elo_1500_1600.pth\n",
            "\n",
            "üéØ Training on Elo bucket: 1600‚Äì1700\n",
            "Epoch 1/5 - Loss: 8.3210 - Top-1 Acc: 0.00%\n",
            "Epoch 2/5 - Loss: 8.3170 - Top-1 Acc: 0.00%\n",
            "Epoch 3/5 - Loss: 8.3143 - Top-1 Acc: 0.00%\n",
            "Epoch 4/5 - Loss: 8.3098 - Top-1 Acc: 0.56%\n",
            "Epoch 5/5 - Loss: 8.3053 - Top-1 Acc: 0.56%\n",
            "‚úÖ Model saved to maia_finetuned_elo_1600_1700.pth\n",
            "\n",
            "üéØ Training on Elo bucket: 1700‚Äì1800\n",
            "‚ö†Ô∏è Skipping 1700-1800 (only 0 samples)\n",
            "\n",
            "üéØ Training on Elo bucket: 1800‚Äì1900\n",
            "‚ö†Ô∏è Skipping 1800-1900 (only 0 samples)\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess dataset\n",
        "df = extract_fens_and_moves(\"/content/maia1_sample.pgn\", max_games=1000)\n",
        "\n",
        "# Define Elo ranges (e.g., buckets of 100)\n",
        "elo_ranges = [(1400, 1500), (1500, 1600), (1600, 1700), (1700, 1800), (1800, 1900)]\n",
        "\n",
        "# Train and save one model per Elo bucket\n",
        "train_over_elo_buckets(df, uci_to_idx, MaiaCNN, elo_ranges, epochs=5, save_prefix=\"maia_finetuned\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Evaluation: Top-K Accuracy by Elo Bucket\n",
        "\n",
        "After training a separate `MaiaCNN` model for each Elo range, this block evaluates each model's performance using **Top-1**, **Top-3**, and **Top-5 accuracy** on its corresponding Elo bucket.\n",
        "\n",
        "### ‚úÖ Step 1: Evaluation Function `evaluate_topk_by_bucket(...)`\n",
        "\n",
        "For each saved model (e.g., `maia_finetuned_elo_1500_1600.pth`):\n",
        "- Loads the trained model\n",
        "- Filters the dataset to match the corresponding Elo bucket\n",
        "- Measures how often the model‚Äôs top prediction matches the true move (`Top-1`)\n",
        "- Also tracks whether the true move appears in the model‚Äôs top 3 or top 5 guesses (`Top-3`, `Top-5`)\n",
        "- Accuracy is computed as a percentage and stored for each Elo bucket\n",
        "\n",
        "### ‚úÖ Step 2: Plotting Function `plot_topk_accuracies(...)`\n",
        "\n",
        "Generates a **grouped bar chart** showing:\n",
        "- **Top-1**, **Top-3**, and **Top-5 accuracy**\n",
        "- For each Elo bucket from the training phase (e.g., 1400‚Äì1500, 1500‚Äì1600, etc.)\n",
        "\n",
        "This visual summary helps answer:\n",
        "- How consistent is the model‚Äôs performance across skill levels?\n",
        "- Are lower- or higher-Elo models more human-aligned?\n",
        "- Does Top-K accuracy improve with player skill?\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Output\n",
        "\n",
        "This chart highlights model accuracy trends and may be used to:\n",
        "- Analyze the benefits of Elo-specific fine-tuning\n",
        "- Justify skill-aware modeling choices\n",
        "- Inform adaptive training systems or Elo-calibrated model switching\n",
        "\n",
        "> ‚ö†Ô∏è Models are only evaluated on positions within their trained Elo range, ensuring fairness and consistency.\n",
        "\n"
      ],
      "metadata": {
        "id": "wstr17COkFEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "7dFBdxznqQu0",
        "outputId": "8fd8ff4c-8bed-429b-8b00-5eb6e4e4cd7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Skipping 1700-1800 (model not found)\n",
            "‚ö†Ô∏è Skipping 1800-1900 (model not found)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def evaluate_topk_by_bucket(df, uci_to_idx, model_class, elo_ranges, batch_size=64):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    topk_results = {\"bucket\": [], \"top1\": [], \"top3\": [], \"top5\": []}\n",
        "\n",
        "    for elo_min, elo_max in elo_ranges:\n",
        "        path = f\"maia_finetuned_elo_{elo_min}_{elo_max}.pth\"\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"‚ö†Ô∏è Skipping {elo_min}-{elo_max} (model not found)\")\n",
        "            continue\n",
        "\n",
        "        # Load model\n",
        "        model = model_class(num_classes=len(uci_to_idx)).to(device)\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        model.eval()\n",
        "\n",
        "        # Filter data\n",
        "        bucket_df = df[\n",
        "            (df[\"white_elo\"].between(elo_min, elo_max)) &\n",
        "            (df[\"black_elo\"].between(elo_min, elo_max)) &\n",
        "            (df[\"move\"].isin(uci_to_idx))\n",
        "        ].reset_index(drop=True)\n",
        "\n",
        "        if len(bucket_df) == 0:\n",
        "            continue\n",
        "\n",
        "        # Dataset\n",
        "        class EvalDataset(Dataset):\n",
        "            def __init__(self, df): self.df = df\n",
        "            def __len__(self): return len(self.df)\n",
        "            def __getitem__(self, idx):\n",
        "                row = self.df.iloc[idx]\n",
        "                return (\n",
        "                    fen_to_tensor(row.fen),\n",
        "                    torch.tensor([row.white_elo / 3000, row.black_elo / 3000], dtype=torch.float32),\n",
        "                    uci_to_idx[row.move]\n",
        "                )\n",
        "\n",
        "        loader = DataLoader(EvalDataset(bucket_df), batch_size=batch_size)\n",
        "\n",
        "        # Evaluate\n",
        "        top1, top3, top5, total = 0, 0, 0, 0\n",
        "        for board_tensor, elo_tensor, move_index in loader:\n",
        "            board_tensor, elo_tensor, move_index = board_tensor.to(device), elo_tensor.to(device), move_index.to(device)\n",
        "            out = model(board_tensor, elo_tensor)\n",
        "            total += len(board_tensor)\n",
        "\n",
        "            top1 += (out.topk(1, dim=1).indices == move_index.view(-1, 1)).any(dim=1).float().sum().item()\n",
        "            top3 += (out.topk(3, dim=1).indices == move_index.view(-1, 1)).any(dim=1).float().sum().item()\n",
        "            top5 += (out.topk(5, dim=1).indices == move_index.view(-1, 1)).any(dim=1).float().sum().item()\n",
        "\n",
        "        topk_results[\"bucket\"].append(f\"{elo_min}-{elo_max}\")\n",
        "        topk_results[\"top1\"].append(100 * top1 / total)\n",
        "        topk_results[\"top3\"].append(100 * top3 / total)\n",
        "        topk_results[\"top5\"].append(100 * top5 / total)\n",
        "\n",
        "    return topk_results\n",
        "def plot_topk_accuracies(results):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    buckets = results[\"bucket\"]\n",
        "    top1 = results[\"top1\"]\n",
        "    top3 = results[\"top3\"]\n",
        "    top5 = results[\"top5\"]\n",
        "    x = range(len(buckets))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar([i - 0.2 for i in x], top1, width=0.2, label=\"Top-1\", color=\"skyblue\")\n",
        "    plt.bar(x, top3, width=0.2, label=\"Top-3\", color=\"orange\")\n",
        "    plt.bar([i + 0.2 for i in x], top5, width=0.2, label=\"Top-5\", color=\"green\")\n",
        "    plt.xticks(x, buckets, rotation=45)\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Top-K Accuracy by Elo Bucket\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "results = evaluate_topk_by_bucket(df, uci_to_idx, MaiaCNN, elo_ranges)\n",
        "plot_topk_accuracies(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÅ MaiaTransformer: Transformer-Based Human Move Predictor\n",
        "\n",
        "This architecture reimagines the Maia CNN as a **Transformer-based model**, enabling it to better capture spatial dependencies and higher-order structure in chess positions. The design leverages the strengths of self-attention to understand long-range interactions between pieces on the board.\n",
        "\n",
        "---\n",
        "\n",
        "### üß± Architecture Overview\n",
        "\n",
        "| Component               | Description |\n",
        "|------------------------|-------------|\n",
        "| **Board Embedding**    | A `Conv2d` layer maps the 12-channel board tensor (one plane per piece type) to a `d_model` dimensional space. Output shape becomes `[B, d_model, 8, 8]`. |\n",
        "| **Flattening**         | Converts spatial features into a sequence: `[B, 64, d_model]` (64 board squares). |\n",
        "| **CLS Token**          | A learned token prepended to the input sequence, used to aggregate global information for classification. |\n",
        "| **Positional Encoding**| A learnable `nn.Parameter` added to encode spatial structure, allowing the transformer to distinguish between squares. |\n",
        "| **Transformer Encoder**| A standard multi-layer `nn.TransformerEncoder` processes the input sequence, capturing square-level interactions via self-attention. |\n",
        "| **Classification Head**| Applies `LayerNorm` + `Linear` projection to the output of the `[CLS]` token to generate logits over 4672 move classes. |\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Input/Output Shapes\n",
        "\n",
        "- **Input**: `board_tensor` ‚Üí `[B, 12, 8, 8]`\n",
        "- **Intermediate**: Transformed to `[B, 65, d_model]` including `[CLS]` token\n",
        "- **Output**: Final prediction logits ‚Üí `[B, 4672]` (UCI move index vocabulary)\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Why Transformers?\n",
        "\n",
        "Transformers allow the model to:\n",
        "- Capture **global board dynamics** better than local convolutions\n",
        "- Learn **interactions between distant pieces** (e.g., queen and king across the board)\n",
        "- Offer flexibility to scale to larger input embeddings or include temporal game context (future extension)\n",
        "\n",
        "> This model variant is experimental and aligns with recent trends in vision-based Transformers (e.g., ViT), adapted here for structured chess input."
      ],
      "metadata": {
        "id": "5OPhV0n5lId3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHgQ1JZ647XX"
      },
      "outputs": [],
      "source": [
        "class MaiaTransformer(nn.Module):\n",
        "    def __init__(self, d_model=512, nhead=8, num_layers=6, num_classes=4672, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # === Board Embedding ===\n",
        "        self.board_embed = nn.Conv2d(12, d_model, kernel_size=3, padding=1)  # [B, d_model, 8, 8]\n",
        "        self.flatten = nn.Flatten(2)  # -> [B, d_model, 64]\n",
        "        self.transpose = lambda x: x.transpose(1, 2)  # -> [B, 64, d_model]\n",
        "\n",
        "        # === Positional Encoding ===\n",
        "        self.positional_encoding = nn.Parameter(torch.randn(65, d_model))  # not 64\n",
        "\n",
        "\n",
        "        # === Transformer Encoder ===\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # === Final Classification ===\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, board_tensor):\n",
        "        # Embed board to d_model dims\n",
        "        x = self.board_embed(board_tensor)  # [B, d_model, 8, 8]\n",
        "        x = self.flatten(x)  # [B, d_model, 64]\n",
        "        x = self.transpose(x)  # [B, 64, d_model]\n",
        "\n",
        "        # Add cls token and positional encoding\n",
        "        B = x.size(0)\n",
        "        cls = self.cls_token.expand(B, -1, -1)  # [B, 1, d_model]\n",
        "        x = torch.cat([cls, x], dim=1)  # [B, 65, d_model]\n",
        "        x = x + self.positional_encoding.unsqueeze(0).expand(B, -1, -1)[:, :x.size(1), :]\n",
        "\n",
        "        # Transformer\n",
        "        x = self.transformer(x)  # [B, 65, d_model]\n",
        "        cls_output = x[:, 0]  # [B, d_model]\n",
        "\n",
        "        return self.head(cls_output)  # [B, num_classes]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÅ Training & Evaluation: MaiaTransformer (Board-Only Input)\n",
        "\n",
        "This block trains the **MaiaTransformer**, a ViT-style transformer architecture for human move prediction in chess, using only the board state as input (Elo information is excluded here).\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è Configuration\n",
        "\n",
        "| Parameter       | Value            |\n",
        "|----------------|------------------|\n",
        "| Model           | `MaiaTransformer` (6 layers, 8 heads, d_model=512) |\n",
        "| Input           | FEN-encoded board ‚Üí 12√ó8√ó8 tensor |\n",
        "| Output classes  | 4672 UCI move indices |\n",
        "| Batch Size      | 64               |\n",
        "| Epochs          | 2                |\n",
        "| Learning Rate   | 0.0005           |\n",
        "| Loss Function   | CrossEntropyLoss |\n",
        "| Optimizer       | Adam             |\n",
        "| Evaluation      | Top-1, Top-3, Top-5 Accuracy |\n",
        "\n",
        "### üéØ Interpretation\n",
        "\n",
        "These results reflect expected early performance from a transformer-based model trained **from scratch** on a small dataset:\n",
        "\n",
        "- Transformers typically require **large datasets** and **longer training schedules** to converge due to their high capacity and lack of inductive biases.\n",
        "- The model has not yet learned meaningful representations of board structure, which is evident from the relatively flat accuracy growth.\n",
        "\n",
        "> ‚ö†Ô∏è Unlike CNNs, transformers do not hard-code spatial locality ‚Äî this makes them more powerful in theory, but also more data-hungry.\n",
        "\n",
        "---\n",
        "\n",
        "### üíæ Output\n",
        "\n",
        "The trained model is saved to disk as: maia_transformer.pth\n",
        "\n"
      ],
      "metadata": {
        "id": "HCOQYuL9la8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aes8rMCr5Anl",
        "outputId": "edc06549-596b-4da9-e458-6fe36806a7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss: 6.8677\n",
            "Top-1 Acc: 1.08% | Top-3 Acc: 3.15% | Top-5 Acc: 5.56%\n",
            "Epoch 2/5 - Loss: 6.6284\n",
            "Top-1 Acc: 1.66% | Top-3 Acc: 4.42% | Top-5 Acc: 6.64%\n"
          ]
        }
      ],
      "source": [
        "# === Top-k Accuracy Helper ===\n",
        "def top_k_accuracy(outputs, targets, k=5):\n",
        "    _, topk_preds = torch.topk(outputs, k, dim=1)\n",
        "    matches = topk_preds.eq(targets.view(-1, 1))\n",
        "    return matches.any(dim=1).float().mean().item()\n",
        "\n",
        "# === Config ===\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 2\n",
        "LR = 0.0005\n",
        "NUM_CLASSES = 4672\n",
        "\n",
        "# === Dataset & Split ===\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
        "\n",
        "# === Model, Loss, Optimizer ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MaiaTransformer(num_classes=NUM_CLASSES).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# === Training + Validation Loop ===\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for board_tensor, _, move_index in train_loader:  # discard elo_tensor\n",
        "        board_tensor, move_index = board_tensor.to(device), move_index.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(board_tensor)\n",
        "        loss = criterion(outputs, move_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # === Validation ===\n",
        "    model.eval()\n",
        "    top1_correct = 0\n",
        "    top3_acc = 0\n",
        "    top5_acc = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for board_tensor, _, move_index in val_loader:\n",
        "            board_tensor, move_index = board_tensor.to(device), move_index.to(device)\n",
        "            outputs = model(board_tensor)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            top1_correct += (preds == move_index).sum().item()\n",
        "            top3_acc += top_k_accuracy(outputs, move_index, k=3) * move_index.size(0)\n",
        "            top5_acc += top_k_accuracy(outputs, move_index, k=5) * move_index.size(0)\n",
        "            total += move_index.size(0)\n",
        "\n",
        "    top1 = top1_correct / total\n",
        "    top3 = top3_acc / total\n",
        "    top5 = top5_acc / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Top-1 Acc: {top1*100:.2f}% | Top-3 Acc: {top3*100:.2f}% | Top-5 Acc: {top5*100:.2f}%\")\n",
        "\n",
        "# === Save model ===\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, \"maia_transformer.pth\")\n",
        "\n",
        "print(\"‚úÖ Model saved to maia_transformer.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTVpj5AvP26O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}